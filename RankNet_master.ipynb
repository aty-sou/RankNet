{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kanazawaatsuya/imp/MQ2007/RankNet\n"
     ]
    }
   ],
   "source": [
    "# cd\n",
    "import os\n",
    "path = os.getcwd()\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ptranking.data.data_utils import LTRDataset, SPLIT_TYPE\n",
    "data_id = 'MQ2007_Super'\n",
    "#MQ2007内にあるもの\n",
    "fold1 = LTRDataset(SPLIT_TYPE.Train, data_id=data_id, file='S1.txt', batch_size=1, shuffle=True, presort=True, data_dict=None, eval_dict=None, buffer=False)\n",
    "fold2 = LTRDataset(SPLIT_TYPE.Train, data_id=data_id, file='S2.txt', batch_size=1, shuffle=True, presort=True, data_dict=None, eval_dict=None, buffer=False)\n",
    "fold3 = LTRDataset(SPLIT_TYPE.Train, data_id=data_id, file='S3.txt', batch_size=1, shuffle=True, presort=True, data_dict=None, eval_dict=None, buffer=False)\n",
    "fold4 = LTRDataset(SPLIT_TYPE.Train, data_id=data_id, file='S4.txt', batch_size=1, shuffle=True, presort=True, data_dict=None, eval_dict=None, buffer=False)\n",
    "fold5 = LTRDataset(SPLIT_TYPE.Train, data_id=data_id, file='S5.txt', batch_size=1, shuffle=True, presort=True, data_dict=None, eval_dict=None, buffer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [nn.Linear(46, 128),\n",
    "          nn.ReLU(),\n",
    "          nn.Linear(128, 64),\n",
    "          nn.ReLU(),\n",
    "          nn.Linear(64, 32),\n",
    "          nn.ReLU(),\n",
    "          nn.Linear(32, 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RankNet(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super(RankNet, self).__init__()\n",
    "        self.model = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, batch_ranking, label):\n",
    "        batch_pred = self.model(batch_ranking) # [1, 40, 1]\n",
    "        batch_sij = torch.squeeze(batch_pred, 0) - torch.squeeze(batch_pred, 2) # [40, 40]\n",
    "        batch_pij = 1.0 / (1.0 + torch.exp(-batch_sij)) # [40, 40]\n",
    "\n",
    "        label_dim = torch.squeeze(label)\n",
    "        label_diffs = torch.unsqueeze(label_dim, 1) - label # [40,40]\n",
    "        batch_Sij = torch.clamp(label_diffs, -1, 1)\n",
    "        l_pij = 0.5 * (1.0 + batch_Sij)\n",
    "\n",
    "        batch_loss = F.binary_cross_entropy(input=torch.triu(batch_pij, diagonal=1), target=torch.triu(l_pij, diagonal=1), reduction='mean')    \n",
    "        \n",
    "        return batch_loss\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ndcg\n",
    "def DCG(sorted_labels, cutoff):\n",
    "    denoms = torch.log2(torch.arange(2, cutoff+2))\n",
    "    nums = torch.pow(2, sorted_labels[0:cutoff])-1\n",
    "    dcg = sum(nums / denoms)\n",
    "    return dcg\n",
    "\n",
    "def nDCG(ideal, pred, k):\n",
    "    dcg_f = DCG(pred, k)\n",
    "    dcg = DCG(ideal, k)\n",
    "    nDCG = dcg_f / dcg\n",
    "    return nDCG\n",
    "\n",
    "def compute_ndcg(score, label, cutoff):\n",
    "    batch_pred = model.predict(score)\n",
    "    idx = torch.argsort(torch.squeeze(batch_pred),descending = True)\n",
    "    pred_sorted_labels = torch.squeeze(label)[idx]\n",
    "    ndcg = torch.nan_to_num(nDCG(torch.squeeze(label), pred_sorted_labels, cutoff))\n",
    "    \n",
    "    return ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(data):\n",
    "    with torch.no_grad():\n",
    "        ndcg_sum = 0\n",
    "        for _,batch_ranking,label in data:\n",
    "        #computes ndcg\n",
    "            ndcg = compute_ndcg(batch_ranking,label,5)\n",
    "            ndcg_sum += ndcg  \n",
    "    ndcg_sum /= len(data)\n",
    "    return(ndcg_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop2(n_epochs,optimizer,model,train):\n",
    "    \n",
    "    \n",
    "    # モデルの訓練\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        \n",
    "        # クエリごとの訓練\n",
    "        batch_loss = 0\n",
    "        batch_ndcg = 0\n",
    "        for _,batch_ranking,label in train:\n",
    "            batch_loss += model.forward(batch_ranking=batch_ranking, label=label)\n",
    "            #print(compute_ndcg(batch_ranking,label,5))\n",
    "            batch_ndcg += compute_ndcg(batch_ranking,label,5)\n",
    "                    \n",
    "        fold_loss_mean = batch_loss / len(fold1)\n",
    "        fold_ndcg_mean = batch_ndcg / len(fold1)\n",
    "        \n",
    "        print('epoch:{0}, loss:{1}, ndcg:{2}'.format(epoch, fold_loss_mean, fold_ndcg_mean))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        fold_loss_mean.backward()\n",
    "        optimizer.step()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c=fold1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0025, 0.3333, 0.0000,  ..., 0.5000, 0.5057, 0.0000],\n",
      "         [0.0305, 0.1667, 0.0000,  ..., 0.3333, 0.2759, 0.0000],\n",
      "         [0.0052, 0.0000, 0.2500,  ..., 0.6667, 0.3678, 0.0000],\n",
      "         ...,\n",
      "         [0.0163, 0.0000, 0.0000,  ..., 1.0000, 0.7471, 0.0000],\n",
      "         [0.0291, 0.1667, 0.0000,  ..., 0.5000, 0.3793, 0.0000],\n",
      "         [1.0000, 0.0000, 0.0000,  ..., 1.0000, 0.6897, 0.0000]]])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "print(b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5531)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_ndcg(b,c,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('10',\n",
       " tensor([[[0.0025, 0.3333, 0.0000,  ..., 0.5000, 0.5057, 0.0000],\n",
       "          [0.0305, 0.1667, 0.0000,  ..., 0.3333, 0.2759, 0.0000],\n",
       "          [0.0052, 0.0000, 0.2500,  ..., 0.6667, 0.3678, 0.0000],\n",
       "          ...,\n",
       "          [0.0163, 0.0000, 0.0000,  ..., 1.0000, 0.7471, 0.0000],\n",
       "          [0.0291, 0.1667, 0.0000,  ..., 0.5000, 0.3793, 0.0000],\n",
       "          [1.0000, 0.0000, 0.0000,  ..., 1.0000, 0.6897, 0.0000]]]),\n",
       " tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0.]]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:0.33804160356521606, ndcg:0.27715516090393066\n",
      "epoch:2, loss:0.33804139494895935, ndcg:0.2775244116783142\n",
      "epoch:3, loss:0.33804115653038025, ndcg:0.2775244116783142\n",
      "epoch:4, loss:0.3380410075187683, ndcg:0.27750131487846375\n",
      "epoch:5, loss:0.3380407691001892, ndcg:0.2770342230796814\n",
      "epoch:6, loss:0.3380405604839325, ndcg:0.2770342230796814\n",
      "epoch:7, loss:0.33804047107696533, ndcg:0.27706366777420044\n",
      "epoch:8, loss:0.3380402624607086, ndcg:0.276743620634079\n",
      "epoch:9, loss:0.3380400538444519, ndcg:0.27651485800743103\n",
      "epoch:10, loss:0.3380397856235504, ndcg:0.27651485800743103\n",
      "epoch:11, loss:0.33803969621658325, ndcg:0.27690187096595764\n",
      "epoch:12, loss:0.3380395174026489, ndcg:0.2768726348876953\n",
      "epoch:13, loss:0.3380393087863922, ndcg:0.2768190801143646\n",
      "epoch:14, loss:0.3380391299724579, ndcg:0.2769017517566681\n",
      "epoch:15, loss:0.33803895115852356, ndcg:0.2769017517566681\n",
      "epoch:16, loss:0.3380386531352997, ndcg:0.277054101228714\n",
      "epoch:17, loss:0.33803850412368774, ndcg:0.277054101228714\n",
      "epoch:18, loss:0.3380383551120758, ndcg:0.2770524024963379\n",
      "epoch:19, loss:0.33803820610046387, ndcg:0.27739283442497253\n",
      "epoch:20, loss:0.33803802728652954, ndcg:0.2776828706264496\n",
      "epoch:21, loss:0.3380376994609833, ndcg:0.2778138518333435\n",
      "epoch:22, loss:0.33803752064704895, ndcg:0.27738669514656067\n",
      "epoch:23, loss:0.33803728222846985, ndcg:0.2773430347442627\n",
      "epoch:24, loss:0.3380371034145355, ndcg:0.2773430347442627\n",
      "epoch:25, loss:0.33803677558898926, ndcg:0.2769739031791687\n",
      "epoch:26, loss:0.33803659677505493, ndcg:0.2769300639629364\n",
      "epoch:27, loss:0.33803635835647583, ndcg:0.2769300639629364\n",
      "epoch:28, loss:0.33803609013557434, ndcg:0.27691224217414856\n",
      "epoch:29, loss:0.33803591132164, ndcg:0.27704325318336487\n",
      "epoch:30, loss:0.3380357325077057, ndcg:0.27730950713157654\n",
      "epoch:31, loss:0.338035523891449, ndcg:0.27769654989242554\n",
      "epoch:32, loss:0.33803531527519226, ndcg:0.27769654989242554\n",
      "epoch:33, loss:0.3380352556705475, ndcg:0.27769654989242554\n",
      "epoch:34, loss:0.33803507685661316, ndcg:0.277809739112854\n",
      "epoch:35, loss:0.33803480863571167, ndcg:0.277809739112854\n",
      "epoch:36, loss:0.33803462982177734, ndcg:0.27801424264907837\n",
      "epoch:37, loss:0.33803442120552063, ndcg:0.27805790305137634\n",
      "epoch:38, loss:0.3380342721939087, ndcg:0.2776328921318054\n",
      "epoch:39, loss:0.3380340337753296, ndcg:0.2779500484466553\n",
      "epoch:40, loss:0.3380337953567505, ndcg:0.2779500484466553\n",
      "epoch:41, loss:0.3380335569381714, ndcg:0.27758079767227173\n",
      "epoch:42, loss:0.33803340792655945, ndcg:0.2775186002254486\n",
      "epoch:43, loss:0.3380332887172699, ndcg:0.2776932716369629\n",
      "epoch:44, loss:0.3380330801010132, ndcg:0.2776932716369629\n",
      "epoch:45, loss:0.3380328118801117, ndcg:0.27784934639930725\n",
      "epoch:46, loss:0.33803269267082214, ndcg:0.27799299359321594\n",
      "epoch:47, loss:0.33803239464759827, ndcg:0.27803927659988403\n",
      "epoch:48, loss:0.3380321264266968, ndcg:0.277912974357605\n",
      "epoch:49, loss:0.33803194761276245, ndcg:0.277912974357605\n",
      "epoch:50, loss:0.33803170919418335, ndcg:0.278300017118454\n",
      "epoch:51, loss:0.33803150057792664, ndcg:0.2780967354774475\n",
      "epoch:52, loss:0.3380313217639923, ndcg:0.2780967354774475\n",
      "epoch:53, loss:0.338031142950058, ndcg:0.2780967354774475\n",
      "epoch:54, loss:0.33803099393844604, ndcg:0.27848297357559204\n",
      "epoch:55, loss:0.33803072571754456, ndcg:0.27848297357559204\n",
      "epoch:56, loss:0.33803048729896545, ndcg:0.27873313426971436\n",
      "epoch:57, loss:0.3380303382873535, ndcg:0.27873313426971436\n",
      "epoch:58, loss:0.33803021907806396, ndcg:0.27877679467201233\n",
      "epoch:59, loss:0.3380299210548401, ndcg:0.27875596284866333\n",
      "epoch:60, loss:0.33802974224090576, ndcg:0.27845609188079834\n",
      "epoch:61, loss:0.33802950382232666, ndcg:0.27845609188079834\n",
      "epoch:62, loss:0.3380293846130371, ndcg:0.27845609188079834\n",
      "epoch:63, loss:0.33802929520606995, ndcg:0.2784707248210907\n",
      "epoch:64, loss:0.338029146194458, ndcg:0.2784707248210907\n",
      "epoch:65, loss:0.33802884817123413, ndcg:0.2784707248210907\n",
      "epoch:66, loss:0.33802857995033264, ndcg:0.2784707248210907\n",
      "epoch:67, loss:0.3380284309387207, ndcg:0.2780836820602417\n",
      "epoch:68, loss:0.3380282521247864, ndcg:0.2780836820602417\n",
      "epoch:69, loss:0.33802804350852966, ndcg:0.27824196219444275\n",
      "epoch:70, loss:0.33802786469459534, ndcg:0.278085857629776\n",
      "epoch:71, loss:0.33802762627601624, ndcg:0.2774183452129364\n",
      "epoch:72, loss:0.3380274474620819, ndcg:0.2774183452129364\n",
      "epoch:73, loss:0.3380272686481476, ndcg:0.277031272649765\n",
      "epoch:74, loss:0.3380269408226013, ndcg:0.2772178649902344\n",
      "epoch:75, loss:0.3380267322063446, ndcg:0.2771584093570709\n",
      "epoch:76, loss:0.3380265533924103, ndcg:0.27824708819389343\n",
      "epoch:77, loss:0.33802634477615356, ndcg:0.2778778672218323\n",
      "epoch:78, loss:0.3380261957645416, ndcg:0.2778778672218323\n",
      "epoch:79, loss:0.3380260169506073, ndcg:0.2781120240688324\n",
      "epoch:80, loss:0.3380257785320282, ndcg:0.2781120240688324\n",
      "epoch:81, loss:0.3380255401134491, ndcg:0.27868160605430603\n",
      "epoch:82, loss:0.33802536129951477, ndcg:0.27865850925445557\n",
      "epoch:83, loss:0.33802515268325806, ndcg:0.2794150412082672\n",
      "epoch:84, loss:0.3380250036716461, ndcg:0.2794150412082672\n",
      "epoch:85, loss:0.3380248248577118, ndcg:0.2794150412082672\n",
      "epoch:86, loss:0.3380245566368103, ndcg:0.2798605263233185\n",
      "epoch:87, loss:0.33802443742752075, ndcg:0.2797911763191223\n",
      "epoch:88, loss:0.33802422881126404, ndcg:0.2797911763191223\n",
      "epoch:89, loss:0.3380240201950073, ndcg:0.28007251024246216\n",
      "epoch:90, loss:0.3380237817764282, ndcg:0.28011634945869446\n",
      "epoch:91, loss:0.3380236029624939, ndcg:0.2800469994544983\n",
      "epoch:92, loss:0.3380233347415924, ndcg:0.2805825173854828\n",
      "epoch:93, loss:0.3380231261253357, ndcg:0.2805825173854828\n",
      "epoch:94, loss:0.33802294731140137, ndcg:0.2805825173854828\n",
      "epoch:95, loss:0.33802276849746704, ndcg:0.2809988260269165\n",
      "epoch:96, loss:0.3380225598812103, ndcg:0.28156203031539917\n",
      "epoch:97, loss:0.3380223512649536, ndcg:0.2814118266105652\n",
      "epoch:98, loss:0.3380222022533417, ndcg:0.2813681662082672\n",
      "epoch:99, loss:0.33802202343940735, ndcg:0.2809811532497406\n",
      "epoch:100, loss:0.338021844625473, ndcg:0.2809811532497406\n"
     ]
    }
   ],
   "source": [
    "training_loop2(\n",
    "    n_epochs = 100,\n",
    "    optimizer = torch.optim.SGD(model.parameters(),lr = 0.01),\n",
    "    model = model,\n",
    "    train = fold1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs,optimizer,model,data_list):\n",
    "    count = 0\n",
    "    best_ndcg = 0\n",
    "    \n",
    "    while count < len(data_list):\n",
    "        # 最初の3つをtrainに\n",
    "        train = data_list[0]+data_list[1]+data_list[2]\n",
    "        # 1つをvalidationに\n",
    "        val = data_list[3]\n",
    "        # 最後をtestに\n",
    "        test = data_list[4]\n",
    "        \n",
    "        # モデルの訓練\n",
    "        for epoch in range(1, n_epochs + 1):\n",
    "        \n",
    "            # クエリごとの訓練\n",
    "            batch_loss = 0\n",
    "            batch_ndcg = 0\n",
    "            for _,batch_ranking,label in train:\n",
    "                batch_loss += model.forward(batch_ranking=batch_ranking, label=label)\n",
    "                #print(compute_ndcg(batch_ranking,label,5))\n",
    "                batch_ndcg += compute_ndcg(batch_ranking,label,5)\n",
    "                    \n",
    "            fold_loss_mean = batch_loss / (len(data_list[0])+len(data_list[1])+len(data_list[2]))\n",
    "            fold_ndcg_mean = batch_ndcg / (len(data_list[0])+len(data_list[1])+len(data_list[2]))\n",
    "            \n",
    "            if epoch ==1 or epoch%10==0:\n",
    "                print('epoch:{0}, loss:{1}, ndcg:{2}'.format(epoch, fold_loss_mean, fold_ndcg_mean))\n",
    "            \n",
    "            # パラメータ選択\n",
    "            val_loss = 0\n",
    "            val_ndcg = 0\n",
    "            for _,batch_ranking,label in val:\n",
    "                val_loss += model.forward(batch_ranking=batch_ranking, label=label)\n",
    "                val_ndcg += compute_ndcg(batch_ranking,label,5)\n",
    "                \n",
    "            val_loss_mean = val_loss / len(val)\n",
    "            val_ndcg_mean = val_ndcg / len(val)    \n",
    "                \n",
    "            if val_ndcg_mean > best_ndcg:\n",
    "                best_ndcg = val_ndcg_mean\n",
    "            \n",
    "                # 訓練したモデルの保存\n",
    "                torch.save(model.state_dict(), 'weight.pth')\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            fold_loss_mean.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        # パラメータの読み込み\n",
    "        param = torch.load('weight.pth')\n",
    "        model.load_state_dict(param)\n",
    "        \n",
    "        #test\n",
    "        test_ndcg = testing(test)\n",
    "        \n",
    "        print('test:{0}'.format(test_ndcg))\n",
    "        \n",
    "        #　右にひとつシフト ([1,2,3,4,5] -> [5,1,2,3,4]となる)\n",
    "        data_list.insert(0,data_list.pop())\n",
    "        \n",
    "#         if epoch%10==0:\n",
    "#             print(\"epoch: \", epoch, \"loss: \", epoch_loss, \"ndcg: \", epoch_ndcg)\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = [fold1,fold2,fold3,fold4,fold5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# クラスのインスタンス化\n",
    "model = RankNet(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:0.33804816007614136, ndcg:0.2129535973072052\n",
      "epoch:10, loss:0.3380464017391205, ndcg:0.21400970220565796\n",
      "epoch:20, loss:0.33804401755332947, ndcg:0.21507927775382996\n",
      "epoch:30, loss:0.3380418121814728, ndcg:0.21627427637577057\n",
      "epoch:40, loss:0.33803996443748474, ndcg:0.218105748295784\n",
      "epoch:50, loss:0.33803796768188477, ndcg:0.21888558566570282\n",
      "epoch:60, loss:0.33803579211235046, ndcg:0.2204192578792572\n",
      "epoch:70, loss:0.3380337357521057, ndcg:0.22214770317077637\n",
      "epoch:80, loss:0.3380317687988281, ndcg:0.2235986590385437\n",
      "epoch:90, loss:0.338029682636261, ndcg:0.224581778049469\n",
      "epoch:100, loss:0.33802759647369385, ndcg:0.225375235080719\n",
      "test:0.2294071763753891\n",
      "epoch:1, loss:0.33805733919143677, ndcg:0.23191629350185394\n",
      "epoch:10, loss:0.3380555808544159, ndcg:0.2341095507144928\n",
      "epoch:20, loss:0.3380531668663025, ndcg:0.2361796349287033\n",
      "epoch:30, loss:0.33805134892463684, ndcg:0.23738986253738403\n",
      "epoch:40, loss:0.33804914355278015, ndcg:0.23919181525707245\n",
      "epoch:50, loss:0.3380470871925354, ndcg:0.24046093225479126\n",
      "epoch:60, loss:0.33804506063461304, ndcg:0.2423636019229889\n",
      "epoch:70, loss:0.3380430340766907, ndcg:0.2442573755979538\n",
      "epoch:80, loss:0.33804064989089966, ndcg:0.2457537055015564\n",
      "epoch:90, loss:0.33803871273994446, ndcg:0.24691550433635712\n",
      "epoch:100, loss:0.3380364179611206, ndcg:0.24839863181114197\n",
      "test:0.2208268642425537\n",
      "epoch:1, loss:0.33803388476371765, ndcg:0.22798480093479156\n",
      "epoch:10, loss:0.3380318582057953, ndcg:0.22995759546756744\n",
      "epoch:20, loss:0.33802998065948486, ndcg:0.23174148797988892\n",
      "epoch:30, loss:0.33802780508995056, ndcg:0.2331756055355072\n",
      "epoch:40, loss:0.3380261957645416, ndcg:0.2351100593805313\n",
      "epoch:50, loss:0.338023841381073, ndcg:0.23591168224811554\n",
      "epoch:60, loss:0.3380216956138611, ndcg:0.2377420961856842\n",
      "epoch:70, loss:0.3380197286605835, ndcg:0.2402326464653015\n",
      "epoch:80, loss:0.3380175828933716, ndcg:0.24133852124214172\n",
      "epoch:90, loss:0.33801570534706116, ndcg:0.2422952800989151\n",
      "epoch:100, loss:0.3380136787891388, ndcg:0.24327130615711212\n",
      "test:0.22020430862903595\n",
      "epoch:1, loss:0.33795955777168274, ndcg:0.23330236971378326\n",
      "epoch:10, loss:0.3379577100276947, ndcg:0.23382583260536194\n",
      "epoch:20, loss:0.3379558324813843, ndcg:0.2354578971862793\n",
      "epoch:30, loss:0.3379538357257843, ndcg:0.23802784085273743\n",
      "epoch:40, loss:0.3379518985748291, ndcg:0.23849588632583618\n",
      "epoch:50, loss:0.33794987201690674, ndcg:0.23984582722187042\n",
      "epoch:60, loss:0.3379480540752411, ndcg:0.24074816703796387\n",
      "epoch:70, loss:0.3379460573196411, ndcg:0.24221467971801758\n",
      "epoch:80, loss:0.33794426918029785, ndcg:0.24286481738090515\n",
      "epoch:90, loss:0.3379421532154083, ndcg:0.2439768761396408\n",
      "epoch:100, loss:0.3379400670528412, ndcg:0.2454364001750946\n",
      "test:0.25657203793525696\n",
      "epoch:1, loss:0.33794286847114563, ndcg:0.24435967206954956\n",
      "epoch:10, loss:0.33794084191322327, ndcg:0.2449781745672226\n",
      "epoch:20, loss:0.33793890476226807, ndcg:0.24533309042453766\n",
      "epoch:30, loss:0.33793705701828003, ndcg:0.24635052680969238\n",
      "epoch:40, loss:0.33793479204177856, ndcg:0.24617208540439606\n",
      "epoch:50, loss:0.33793288469314575, ndcg:0.24755524098873138\n",
      "epoch:60, loss:0.33793091773986816, ndcg:0.24845951795578003\n",
      "epoch:70, loss:0.33792880177497864, ndcg:0.24956676363945007\n",
      "epoch:80, loss:0.3379268944263458, ndcg:0.2510477900505066\n",
      "epoch:90, loss:0.33792462944984436, ndcg:0.2517324984073639\n",
      "epoch:100, loss:0.33792269229888916, ndcg:0.2523496448993683\n",
      "test:0.27562037110328674\n"
     ]
    }
   ],
   "source": [
    "training_loop(\n",
    "    n_epochs = 100,\n",
    "    optimizer = torch.optim.SGD(model.parameters(),lr = 0.01),\n",
    "    model = model,\n",
    "    data_list = data_list,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
